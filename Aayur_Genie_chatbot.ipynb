{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8675489,"sourceType":"datasetVersion","datasetId":5200042}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Scraping Dataset from Internet","metadata":{}},{"cell_type":"code","source":"import os\nimport requests\nfrom bs4 import BeautifulSoup\nfrom langdetect import detect\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Set the search queries\nsearch_queries = [\n    \"Ayurveda Herbs\", \"Ayurveda Medicines\", \"Ayurveda Diseases\",\n    \"Ayurveda Treatments\", \"Ayurveda Therapy\", \"Ayurveda Nutrition\", \"Ayurveda Diet\",\n    \"Ayurveda Lifestyle\", \"Ayurveda Practices\", \"Ayurveda Yoga\", \"Ayurveda Massage\",\n    \"Ayurveda Remedies\", \"Ayurveda Detox\", \"Ayurveda Panchakarma\", \"Ayurveda Doshas\",\n    \"Ayurveda Vata\", \"Ayurveda Pitta\", \"Ayurveda Kapha\", \"Ayurveda Body Types\",\n    \"Ayurveda Holistic Health\", \"Ayurveda Wellness\", \"Ayurveda Skin Care\",\n    \"Ayurveda Hair Care\", \"Ayurveda Oils\", \"Ayurveda Spices\", \"Ayurveda Immunity\",\n    \"Ayurveda Stress Relief\", \"Ayurveda Meditation\", \"Ayurveda Natural Healing\",\n    \"Ayurveda Cleansing\", \"Ayurveda Weight Loss\", \"Ayurveda Anti-aging\",\n    \"Ayurveda Pain Relief\", \"Ayurveda Sleep Disorders\", \"Ayurveda Mental Health\",\n    \"Ayurveda Chronic Illness\", \"Ayurveda Diabetes\", \"Ayurveda Hypertension\",\n    \"Ayurveda Heart Health\", \"Ayurveda Respiratory Health\", \"Ayurveda Digestive Health\",\n    \"Ayurveda Joint Health\", \"Ayurveda Bone Health\", \"Ayurveda Eye Health\",\n    \"Ayurveda Ear Health\", \"Ayurveda Oral Health\", \"Ayurveda Women's Health\",\n    \"Ayurveda Men's Health\", \"Ayurveda Children's Health\", \"Ayurveda Seasonal Regimen\",\n    \"Ayurveda Daily Routine\", \"Ayurveda Beauty Tips\", \"Ayurveda Hair Growth\",\n    \"Ayurveda Weight Gain\", \"Ayurveda Healthy Recipes\", \"Ayurveda Cooking\",\n    \"Ayurveda Herbal Teas\", \"Ayurveda Drinks\", \"Ayurveda Supplements\",\n    \"Ayurveda Organic Products\", \"Ayurveda Essential Oils\", \"Ayurveda Plants\",\n    \"Ayurveda Seeds\", \"Ayurveda Fruits\", \"Ayurveda Vegetables\", \"Ayurveda Roots\",\n    \"Ayurveda Leaves\", \"Ayurveda Flowers\", \"Ayurveda Shrubs\", \"Ayurveda Trees\",\n    \"Ayurveda Healing Properties\", \"Ayurveda Traditional Medicine\", \"Ayurveda History\",\n    \"Ayurveda Philosophy\", \"Ayurveda Spirituality\", \"Ayurveda Mind-Body Connection\",\n    \"Ayurveda Research\", \"Ayurveda Education\", \"Ayurveda Courses\", \"Ayurveda Certification\",\n    \"Ayurveda Practitioners\", \"Ayurveda Clinics\", \"Ayurveda Hospitals\", \"Ayurveda Tourism\",\n    \"Ayurveda in India\", \"Ayurveda Worldwide\", \"Ayurveda Modern Applications\",\n    \"Ayurveda and Science\", \"Ayurveda Myths\", \"Ayurveda Benefits\", \"Ayurveda for Pets\",\n    \"Ayurveda Environmental Impact\", \"Ayurveda Organic Farming\", \"Ayurveda Farming Practices\",\n    \"Ayurveda Community\", \"Ayurveda Workshops\", \"Ayurveda Events\", \"Ayurveda Blogs\",\n    \"Ayurveda Books\", \"Ayurveda Cosmetics\", \"Ayurveda Bath Products\", \"Ayurveda Baby Care\",\n    \"Ayurveda Pet Care\", \"Ayurveda Animal Health\", \"Ayurveda Home Remedies\", \"Ayurveda Detox Diets\",\n    \"Ayurveda Cold Remedies\", \"Ayurveda Fever Remedies\", \"Ayurveda Headache Remedies\", \"Ayurveda Allergy Remedies\",\n    \"Ayurveda Cancer Support\", \"Ayurveda Immune Boosting\", \"Ayurveda Bone Density\", \"Ayurveda Athletic Performance\",\n    \"Ayurveda Adaptogens\", \"Ayurveda Anti-inflammatory\", \"Ayurveda Cholesterol Management\", \"Ayurveda Blood Pressure\",\n    \"Ayurveda Gut Health\", \"Ayurveda Probiotics\", \"Ayurveda Adaptogen Herbs\", \"Ayurveda Functional Foods\",\n    \"Ayurveda Hormone Balance\", \"Ayurveda Detox Drinks\", \"Ayurveda Smoothies\", \"Ayurveda Soups\",\n    \"Ayurveda Sauces\", \"Ayurveda Spreads\", \"Ayurveda Condiments\", \"Ayurveda Beauty Products\",\n    \"Ayurveda Personal Care\", \"Ayurveda Oral Hygiene\", \"Ayurveda Dental Care\", \"Ayurveda Aroma Therapy\",\n    \"Ayurveda Self-care\", \"Ayurveda Mental Wellness\", \"Ayurveda Journals\", \"Ayurveda Supplements Reviews\",\n    \"Ayurveda Tea Reviews\", \"Ayurveda Essential Oils Reviews\", \"Ayurveda Spa Treatments\", \"Ayurveda Facial Treatments\",\n    \"Ayurveda Eye Treatments\", \"Ayurveda Hearing Treatments\", \"Ayurveda Sleep Therapy\", \"Ayurveda Sleep Hygiene\",\n    \"Ayurveda Fitness\", \"Ayurveda Exercise\", \"Ayurveda Sports Nutrition\", \"Ayurveda Energy Boosters\",\n    \"Ayurveda Superfoods\", \"Ayurveda Hydration\", \"Ayurveda Bone Broth\", \"Ayurveda Herbal Infusions\",\n    \"Ayurveda Balms\", \"Ayurveda Salves\", \"Ayurveda Lotions\", \"Ayurveda Creams\",\n    \"Ayurveda Moisturizers\", \"Ayurveda Face Masks\", \"Ayurveda Hair Masks\", \"Ayurveda Shampoos\",\n    \"Ayurveda Conditioners\", \"Ayurveda Serums\", \"Ayurveda Toners\", \"Ayurveda Cleansers\",\n    \"Ayurveda Facial Oils\", \"Ayurveda Body Oils\", \"Ayurveda Scrubs\", \"Ayurveda Bath Salts\",\n    \"Ayurveda Exfoliators\", \"Ayurveda Foot Care\", \"Ayurveda Hand Care\", \"Ayurveda Nail Care\",\n    \"Ayurveda Lip Care\", \"Ayurveda Anti-Aging Skin Care\", \"Ayurveda Sun Protection\", \"Ayurveda After-Sun Care\",\n    \"Ayurveda Eye Creams\", \"Ayurveda Lip Balms\", \"Ayurveda Beard Oils\", \"Ayurveda Beard Balms\",\n    \"Ayurveda Hair Styling\", \"Ayurveda Hair Treatments\", \"Ayurveda Hair Serums\", \"Ayurveda Hair Oils\",\n    \"Ayurveda Scalp Treatments\", \"Ayurveda Hair Loss Treatments\", \"Ayurveda Hair Growth Serums\", \"Ayurveda Heat Protectants\",\n    \"Ayurveda Hair Dyes\", \"Ayurveda Hair Care Routines\", \"Ayurveda Hair Accessories\", \"Ayurveda Hair Tools\",\n    \"Ayurveda Bath Accessories\", \"Ayurveda Body Brushes\", \"Ayurveda Foot Massagers\", \"Ayurveda Eye Massagers\",\n    \"Ayurveda Face Rollers\", \"Ayurveda Gua Sha\", \"Ayurveda Scalp Massagers\", \"Ayurveda Face Tools\",\n    \"Ayurveda Fitness Equipment\", \"Ayurveda Yoga Mats\", \"Ayurveda Meditation Cushions\", \"Ayurveda Incense\",\n    \"Ayurveda Candles\", \"Ayurveda Crystals\", \"Ayurveda Jewelry\", \"Ayurveda Home Decor\",\n    \"Ayurveda Bedding\", \"Ayurveda Pillows\", \"Ayurveda Throws\", \"Ayurveda Rugs\",\n    \"Ayurveda Wall Art\", \"Ayurveda Kitchenware\", \"Ayurveda Tableware\", \"Ayurveda Cookware\",\n    \"Ayurveda Storage Solutions\", \"Ayurveda Cleaning Products\", \"Ayurveda Natural Cleaners\", \"Ayurveda Sustainable Living\",\n    \"Ayurveda Green Living\", \"Ayurveda Eco-Friendly Products\", \"Ayurveda Zero Waste\", \"Ayurveda Minimalism\",\n    \"Ayurveda Decluttering\", \"Ayurveda Feng Shui\", \"Ayurveda Space Clearing\",\n    \"Ayurveda Plant Care\",\n    \"Ayurveda Gardening\", \"Ayurveda Indoor Plants\", \"Ayurveda Outdoor Plants\", \"Ayurveda Herbal Gardens\",\n    \"Ayurveda Organic Gardening\", \"Ayurveda Garden Design\", \"Ayurveda Companion Planting\", \"Ayurveda Permaculture\",\n    \"Ayurveda Beekeeping\", \"Ayurveda Aquaponics\", \"Ayurveda Hydroponics\", \"Ayurveda Farm-to-Table\",\n    \"Ayurveda Seasonal Eating\", \"Ayurveda Local Food\", \"Ayurveda Farmers Markets\", \"Ayurveda Community Supported Agriculture\",\n    \"Ayurveda Ethical Eating\", \"Ayurveda Food Justice\", \"Ayurveda Food Security\", \"Ayurveda Urban Gardening\",\n    \"Ayurveda Wildcrafting\", \"Ayurveda Foraging\", \"Ayurveda Herbalism\", \"Ayurveda Plant Medicine\",\n    \"Ayurveda Traditional Healing\", \"Ayurveda Indigenous Wisdom\", \"Ayurveda Ancestral Knowledge\", \"Ayurveda Cultural Heritage\",\n    \"Ayurveda Sacred Plants\", \"Ayurveda Rituals\", \"Ayurveda Ceremonies\", \"Ayurveda Festivities\",\n    \"Ayurveda Holidays\", \"Ayurveda Traditions\", \"Ayurveda Legends\", \"Ayurveda Folklore\",\n    \"Ayurveda Mythology\", \"Ayurveda Stories\", \"Ayurveda Wisdom\", \"Ayurveda Teachings\",\n    \"Ayurveda Elders\", \"Ayurveda Lineages\", \"Ayurveda Mentorship\", \"Ayurveda Apprenticeship\",\n    \"Ayurveda Internships\", \"Ayurveda Career Opportunities\", \"Ayurveda Job Listings\", \"Ayurveda Employment\",\n    \"Ayurveda Volunteering\", \"Ayurveda Internships Abroad\", \"Ayurveda Study Abroad\", \"Ayurveda Exchange Programs\",\n    \"Ayurveda Scholarships\", \"Ayurveda Grants\", \"Ayurveda Fellowships\", \"Ayurveda Conferences\",\n    \"Ayurveda Webinars\", \"Ayurveda Online Courses\", \"Ayurveda Distance Learning\", \"Ayurveda E-Learning\",\n    \"Ayurveda Virtual Classes\", \"Ayurveda Digital Resources\", \"Ayurveda Podcasts\", \"Ayurveda Vlogs\",\n    \"Ayurveda YouTube Channels\", \"Ayurveda Instagram Accounts\", \"Ayurveda Facebook Groups\", \"Ayurveda Twitter Accounts\",\n    \"Ayurveda Pinterest Boards\", \"Ayurveda LinkedIn Groups\", \"Ayurveda Networking\", \"Ayurveda Forums\",\n    \"Ayurveda Online Communities\", \"Ayurveda Social Media\",\n    \"Ayurveda Influencers\", \"Ayurveda Brand Ambassadors\",\n    \"Ayurveda Product Reviews\", \"Ayurveda Testimonials\", \"Ayurveda Case Studies\", \"Ayurveda Clinical Trials\",\n    \"Ayurveda Research Papers\", \"Ayurveda Scientific Studies\", \"Ayurveda Journals\", \"Ayurveda Magazines\",\n    \"Ayurveda Newsletters\", \"Ayurveda Press Releases\", \"Ayurveda Media Coverage\", \"Ayurveda News\",\n    \"Ayurveda Trends\", \"Ayurveda Innovations\", \"Ayurveda New Products\", \"Ayurveda Product Launches\",\n    \"Ayurveda Market Analysis\", \"Ayurveda Industry Insights\", \"Ayurveda Business Opportunities\", \"Ayurveda Entrepreneurship\",\n    \"Ayurveda Startups\", \"Ayurveda Investment\", \"Ayurveda Funding\", \"Ayurveda Crowdfunding\",\n    \"Ayurveda Partnerships\", \"Ayurveda Collaborations\", \"Ayurveda Alliances\", \"Ayurveda Joint Ventures\",\n    \"Ayurveda Licensing\", \"Ayurveda Franchising\", \"Ayurveda Retail\", \"Ayurveda E-commerce\",\n    \"Ayurveda Wholesale\", \"Ayurveda Distribution\", \"Ayurveda Supply Chain\", \"Ayurveda Logistics\",\n    \"Ayurveda Export\", \"Ayurveda Import\", \"Ayurveda Trade Shows\", \"Ayurveda Expos\",\n    \"Ayurveda Fairs\", \"Ayurveda Markets\", \"Ayurveda Stores\", \"Ayurveda Boutiques\",\n    \"Ayurveda Pop-Up Shops\", \"Ayurveda Farmers Markets\", \"Ayurveda Craft Fairs\", \"Ayurveda Artisanal Products\",\n    \"Ayurveda Handcrafted Products\", \"Ayurveda Small Businesses\", \"Ayurveda Artisans\", \"Ayurveda Makers\",\n    \"Ayurveda Creators\", \"Ayurveda Designers\", \"Ayurveda Artists\", \"Ayurveda Innovators\",\n    \"Ayurveda Entrepreneurs\", \"Ayurveda Influencers\", \"Ayurveda Thought Leaders\", \"Ayurveda Visionaries\",\n    \"Ayurveda Pioneers\", \"Ayurveda Trailblazers\", \"Ayurveda Changemakers\", \"Ayurveda Advocates\",\n    \"Ayurveda Activists\", \"Ayurveda Leaders\", \"Ayurveda Community Leaders\", \"Ayurveda Nonprofits\",\n    \"Ayurveda NGOs\", \"Ayurveda Philanthropy\", \"Ayurveda Volunteering\", \"Ayurveda Community Service\",\n    \"Ayurveda Social Impact\", \"Ayurveda Social Responsibility\", \"Ayurveda Corporate Social Responsibility\", \"Ayurveda Ethical Practices\",\n    \"Ayurveda Sustainable Practices\", \"Ayurveda Environmental Stewardship\", \"Ayurveda Conservation\", \"Ayurveda Wildlife Protection\",\n    \"Ayurveda Habitat Restoration\", \"Ayurveda Climate Action\", \"Ayurveda Renewable Energy\", \"Ayurveda Green Energy\",\n    \"Ayurveda Energy Efficiency\", \"Ayurveda Carbon Footprint\", \"Ayurveda Carbon Neutrality\", \"Ayurveda Offsetting\",\n    \"Ayurveda Sustainable Design\", \"Ayurveda Eco-Architecture\", \"Ayurveda Green Building\", \"Ayurveda LEED Certification\",\n    \"Ayurveda Healthy Homes\", \"Ayurveda Wellness Architecture\", \"Ayurveda Biophilic Design\", \"Ayurveda Natural Materials\",\n    \"Ayurveda Organic Materials\", \"Ayurveda Non-Toxic Materials\", \"Ayurveda Recycled Materials\", \"Ayurveda Upcycling\",\n    \"Ayurveda Repurposing\", \"Ayurveda Waste Reduction\", \"Ayurveda Waste Management\", \"Ayurveda Composting\",\n    \"Ayurveda Recycling\", \"Ayurveda Circular Economy\", \"Ayurveda Sustainable Economy\", \"Ayurveda Local Economy\",\n    \"Ayurveda Community Economy\", \"Ayurveda Cooperative Economy\", \"Ayurveda Shared Economy\", \"Ayurveda Social Enterprises\",\n    \"Ayurveda B Corps\", \"Ayurveda Fair Trade\", \"Ayurveda Ethical Trade\", \"Ayurveda Transparent Trade\",\n    \"Ayurveda Fair Wages\", \"Ayurveda Worker Rights\", \"Ayurveda Labor Practices\", \"Ayurveda Human Rights\",\n    \"Ayurveda Gender Equality\", \"Ayurveda Racial Equality\", \"Ayurveda Social Justice\", \"Ayurveda Economic Justice\",\n    \"Ayurveda Environmental Justice\", \"Ayurveda Health Equity\", \"Ayurveda Global Health\", \"Ayurveda Public Health\",\n    \"Ayurveda Health Policy\", \"Ayurveda Health Systems\", \"Ayurveda Healthcare Access\", \"Ayurveda Healthcare Delivery\",\n    \"Ayurveda Health Programs\", \"Ayurveda Health Initiatives\", \"Ayurveda Health Campaigns\", \"Ayurveda Health Education\",\n    \"Ayurveda Health Promotion\", \"Ayurveda Disease Prevention\", \"Ayurveda Health Screening\", \"Ayurveda Health Surveillance\",\n    \"Ayurveda Health Data\", \"Ayurveda Health Informatics\", \"Ayurveda Health Technology\", \"Ayurveda Telemedicine\",\n    \"Ayurveda Digital Health\", \"Ayurveda Health Apps\", \"Ayurveda Health Wearables\", \"Ayurveda Health Trackers\",\n    \"Ayurveda Health Analytics\", \"Ayurveda Health Research\", \"Ayurveda Health Studies\", \"Ayurveda Health Publications\",\n    \"Ayurveda Health Conferences\", \"Ayurveda Health Workshops\", \"Ayurveda Health Seminars\", \"Ayurveda Health Training\",\n    \"Ayurveda Health Careers\", \"Ayurveda Health Professions\", \"Ayurveda Health Certifications\", \"Ayurveda Health Licenses\",\n    \"Ayurveda Health Regulations\", \"Ayurveda Health Standards\", \"Ayurveda Health Guidelines\", \"Ayurveda Health Policies\",\n    \"Ayurveda Health Laws\", \"Ayurveda Health Ethics\", \"Ayurveda Health Governance\", \"Ayurveda Health Advocacy\",\n    \"Ayurveda Patient Advocacy\", \"Ayurveda Patient Rights\", \"Ayurveda Patient Safety\", \"Ayurveda Patient Experience\",\n    \"Ayurveda Patient Engagement\", \"Ayurveda Patient Education\", \"Ayurveda Patient Support\", \"Ayurveda Patient Empowerment\",\n    \"Ayurveda Patient-Centered Care\", \"Ayurveda Family-Centered Care\", \"Ayurveda Community-Centered Care\", \"Ayurveda Integrative Care\",\n    \"Ayurveda Coordinated Care\", \"Ayurveda Collaborative Care\", \"Ayurveda Multidisciplinary Care\", \"Ayurveda Holistic Care\",\n    \"Ayurveda Compassionate Care\",\n    \"Ayurveda Palliative Care\", \n    \"Ayurveda Hospice Care\", \"Ayurveda End-of-Life Care\",\n    \"Ayurveda Bereavement Support\", \"Ayurveda Grief Support\", \"Ayurveda Mental Health Support\", \"Ayurveda Peer Support\",\n    \"Ayurveda Support Groups\", \"Ayurveda Counseling\", \"Ayurveda Therapy Services\", \"Ayurveda Coaching\",\n    \"Ayurveda Mentorship Programs\", \"Ayurveda Peer Mentorship\", \"Ayurveda Volunteer Mentorship\", \"Ayurveda Career Mentorship\",\n    \"Ayurveda Business Mentorship\", \"Ayurveda Leadership Mentorship\", \"Ayurveda Academic Mentorship\", \"Ayurveda Student Mentorship\",\n    \"Ayurveda Youth Mentorship\", \"Ayurveda Adult Mentorship\", \"Ayurveda Senior Mentorship\", \"Ayurveda Parent Mentorship\",\n    \"Ayurveda Teacher Mentorship\", \"Ayurveda Faculty Mentorship\", \"Ayurveda Peer Coaching\", \"Ayurveda Life Coaching\",\n    \"Ayurveda Wellness Coaching\", \"Ayurveda Health Coaching\", \"Ayurveda Executive Coaching\", \"Ayurveda Career Coaching\",\n    \"Ayurveda Leadership Coaching\", \"Ayurveda Performance Coaching\", \"Ayurveda Skills Coaching\", \"Ayurveda Personal Development\",\n    \"Ayurveda Self-Improvement\", \"Ayurveda Self-Growth\", \"Ayurveda Self-Help\", \"Ayurveda Self-Care\",\n    \"Ayurveda Mindfulness\", \"Ayurveda Meditation Techniques\", \"Ayurveda Meditation Practices\", \"Ayurveda Guided Meditation\",\n    \"Ayurveda Mindfulness Meditation\", \"Ayurveda Breathwork\", \"Ayurveda Yoga Nidra\", \"Ayurveda Mantras\",\n    \"Ayurveda Chanting\", \"Ayurveda Sound Healing\", \"Ayurveda Sound Therapy\", \"Ayurveda Music Therapy\",\n    \"Ayurveda Art Therapy\", \"Ayurveda Dance Therapy\", \"Ayurveda Movement Therapy\", \"Ayurveda Expressive Arts\",\n    \"Ayurveda Creative Arts\", \"Ayurveda Journaling\", \"Ayurveda Reflection\", \"Ayurveda Contemplation\",\n    \"Ayurveda Diseaseas\",\n    \"Ayurveda Solutions\",\n    \"Yoga\",\n    \"Ayurveda and Yoga\",\n    \"Ayurveda Breathing\",\n    \"Ayurveda Meditation\",\n    \"Ayurvedic Medicine\",\n    \"Ayurvedic Alternatives to Medicine\",\n    \"Ayurvedic Alternatives to Western Medicine\"\n]\n\n\n# Create a directory to store downloaded pages\noutput_dir = \"ayurveda_pages\"\nos.makedirs(output_dir, exist_ok=True)\nimport pickle\n\nwith open(\"visited.pkl\", \"rb\") as f:\n    visited_urls = pickle.load(f)\n# visited_urls = set()\n\n# Directory containing verified texts\nverified_texts_dir = \"texts\"\n\nnum_pages = 3\n# Expanded keywords related to Ayurveda\nayurveda_keywords = [\n    \"Ayurveda\",\n    \"herbal\",\n    \"medicinal\",\n    \"holistic\",\n    \"dosha\",\n    \"panchakarma\",\n    \"vata\",\n    \"pitta\",\n    \"kapha\",\n    \"ayurvedic\",\n    \"western\",\n    \"medicine\",\n    # \"balance\",\n    # \"wellness\",\n    \"alternative medicine\",\n    # \"detoxification\",\n    # \"therapy\",\n    # \"nutrition\",\n    # \"mind-body\",\n    # \"spiritual\",\n    # \"prakriti\",\n    \"shirodhara\",\n    \"abhyanga\",\n    \"rasayana\",\n    # \"natural\",\n    # \"healthy\",\n    # \"meditation\",\n    # \"breathing\",\n]\n\n\ndef load_verified_texts(directory):\n    verified_texts = \"\"\n    for filename in os.listdir(directory):\n        filepath = os.path.join(directory, filename)\n        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n            verified_texts += file.read() + \" \"\n    return verified_texts\n\n\ndef is_english(content):\n    # Check if the content is in English\n    try:\n        return detect(content) == \"en\"\n    except:\n        return False\n\n\ndef contains_ayurveda_keywords(content, threshold=5):\n    # Check if the content contains any of the Ayurveda-related keywords more than a threshold\n    keyword_count = sum(\n        content.lower().count(keyword.lower()) for keyword in ayurveda_keywords\n    )\n    return keyword_count > threshold\n\n\ndef compute_similarity(vectorizer, reference_vector, content):\n    # Transform the content using the pre-fitted vectorizer\n    content_vector = vectorizer.transform([content])\n    # Compute cosine similarity between reference vector and content vector\n    similarity_matrix = cosine_similarity(reference_vector, content_vector)\n    return similarity_matrix[0, 0]\n\n\ndef search_and_download_pages(\n    url,\n    depth,\n    vectorizer,\n    reference_vector,\n    similarity_threshold=0.5,\n    keyword_threshold=3,\n):\n    if depth == 0:\n        return\n\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n        page_content = soup.get_text()  # Extract text content\n\n        # Clean the URL for use as a filename\n        filename = url.replace(\"http://\", \"\").replace(\"https://\", \"\")\n        filename = filename.replace(\"/\", \"_\").replace(\".\", \"_\")\n        filename = f\"{output_dir}/{filename}.txt\"\n\n        # Check if the content is in English, contains Ayurveda keywords, and has high similarity with the reference text\n        if (\n            is_english(page_content)\n            and contains_ayurveda_keywords(page_content, keyword_threshold)\n            and compute_similarity(vectorizer, reference_vector, page_content)\n            > similarity_threshold\n        ):\n            similarity_score = compute_similarity(\n                vectorizer, reference_vector, page_content\n            )\n            if similarity_score > similarity_threshold:\n                # Save the page content to a text file       \n                with open(filename, \"w\", encoding=\"utf-8\") as f:\n                    f.write(page_content)\n                    \n                    \n                    print(\n                        f\"Downloaded page {url} with similarity score {similarity_score}\"\n                    )\n                    result_links = soup.find_all(\"a\", href=True)\n                    for link in result_links:\n                        next_url = link[\"href\"]\n                        if next_url.startswith(\"http\") and next_url not in visited_urls:\n                            visited_urls.add(next_url)  # Mark URL as visited\n                            search_and_download_pages(\n                                next_url,\n                                depth - 1,\n                                vectorizer,\n                                reference_vector,\n                                similarity_threshold,\n                                keyword_threshold,\n                            )\n    except Exception as e:\n        print(f\"Failed to process {url}: {e}\")\n\n\nif __name__ == \"__main__\":\n    # Load the reference text from the verified texts directory\n    reference_text = load_verified_texts(verified_texts_dir)\n\n    # Initialize Count Vectorizer and fit on the reference text\n    vectorizer = CountVectorizer()\n    reference_vector = vectorizer.fit_transform([reference_text])\n\n    # Start with the initial search queries\n    for query in search_queries:\n        search_and_download_pages(\n            f\"https://www.bing.com/search?q={query}\",\n            num_pages,\n            vectorizer,\n            reference_vector,\n        )\n        with open(\"visited.pkl\", \"wb\") as f:\n            pickle.dump(visited_urls, f)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Split Book pdf into smaller text files for embedding","metadata":{}},{"cell_type":"code","source":"import os\nfrom pdf2image import convert_from_path\nimport pytesseract\n\ndef pdf_to_text(input_file, output_dir, file, chunk_size=30000):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    # Convert PDF to images\n    try:\n        images = convert_from_path(input_file)\n    except Exception as e:\n        print(f\"Error converting {input_file} to images: {e}\")\n        return\n    \n    text = \"\"\n\n    # Perform OCR on each image\n    for i, image in enumerate(images):\n        try:\n            text += pytesseract.image_to_string(image)\n        except Exception as e:\n            print(f\"Error performing OCR on page {i + 1} of {input_file}: {e}\")\n\n    # Write text to files in chunks\n    start = 0\n    file_index = 1\n    while start < len(text):\n        end = min(start + chunk_size, len(text))\n        chunk = text[start:end]\n        output_file_path = os.path.join(output_dir, f\"{file}_output_{file_index}.txt\")\n        try:\n            with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n                output_file.write(chunk)\n        except Exception as e:\n            print(f\"Error writing chunk {file_index} to file: {e}\")\n        \n        start = end\n        file_index += 1\n\nif __name__ == \"__main__\":\n    input_folder = \"files\"  # Folder containing PDFs\n    output_dir = \"texts\"    # Folder to save text files\n\n    # Process each PDF file in the input folder\n    for file in os.listdir(input_folder):\n        if file.endswith(\".pdf\"):\n            input_file_path = os.path.join(input_folder, file)\n            print(f\"Processing {input_file_path}\")\n            pdf_to_text(input_file_path, output_dir, file)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Splitting large texts into smaller texts","metadata":{}},{"cell_type":"code","source":"import os\n\ndef split_text_file(input_file, destination=\"texts\", max_chars=300000):\n    # Read the content of the input file\n    with open(input_file, 'r', encoding='utf-8') as file:\n        content = file.read()\n\n    # Calculate the number of parts needed\n    total_chars = len(content)\n    num_parts = (total_chars // max_chars) + 1\n\n    # Ensure the destination directory exists\n    if not os.path.exists(destination):\n        os.makedirs(destination)\n\n    # Split the content and write to separate files\n    base_filename = os.path.basename(input_file)\n    name, ext = os.path.splitext(base_filename)\n    \n    for i in range(num_parts):\n        start_index = i * max_chars\n        end_index = start_index + max_chars\n        part_content = content[start_index:end_index]\n\n        output_file = os.path.join(destination, f\"{name}_part{i + 1}{ext}\")\n        with open(output_file, 'w', encoding='utf-8') as part_file:\n            part_file.write(part_content)\n\n        print(f\"Wrote part {i + 1} to {output_file}\")\n\n# Directory containing text files\ninput_folder = 'files'\noutput_folder = 'texts'\n\n# Iterate through all text files in the directory\nfor file in os.listdir(input_folder):\n    if file.endswith(\".txt\"):\n        input_file_path = os.path.join(input_folder, file)\n        print(f\"Processing {input_file_path}\")\n        split_text_file(input_file_path, destination=output_folder)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Embedding","metadata":{}},{"cell_type":"code","source":"import textwrap\n\nimport google.generativeai as genai\n\nfrom IPython.display import display\nfrom IPython.display import Markdown\n\n\ndef to_markdown(text):\n    text = text.replace('â€¢', '  *')\n    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n\nfrom dotenv import load_dotenv\nload_dotenv(\".env\") \n\nimport os\nfrom langchain.chains import RetrievalQAWithSourcesChain\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import UnstructuredFileLoader\nfrom langchain.vectorstores import FAISS\nfiles=[]\nfor file in os.listdir(\"texts\"):\n    files.append(\"texts/\"+file)\nloaders = UnstructuredFileLoader(files)\ndata = loaders.load() \nlen(data)\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200\n)\n\ndocs = text_splitter.split_documents(data)\n\ngenai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\n\ngemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n\nfor i in range(len(docs)//100):\n    db = FAISS.from_documents(docs[i * 100:min((i + 1) * 100, len(docs))], gemini_embeddings)\n\n    file_path = f\"saved_embeddings/{i + 1}\"\n    db.save_local(file_path)\n    print(f\"Saved embeddings for batch {i + 1} to {file_path}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load embeddings by grouping into one Database","metadata":{}},{"cell_type":"code","source":"base_path = 'saved_embeddings'\nall_dbs = []\n\nfor subfolder in sorted(os.listdir(base_path)):\n    subfolder_path = os.path.join(base_path, subfolder)\n    \n    if os.path.isdir(subfolder_path):\n        db = FAISS.load_local(folder_path=subfolder_path, embeddings=gemini_embeddings, allow_dangerous_deserialization=True)\n        all_dbs.append(db)\n        print(f\"Loaded embeddings from {subfolder_path}\")\n\nif all_dbs:\n    target_db = all_dbs[0]\n\n    # Merge all other databases into the target database\n    for db in all_dbs[1:]:\n        FAISS.merge_from(target_db, db)\n    \n    retriever = target_db.as_retriever(search_kwargs={'k': 3})\nelse:\n    print(\"No databases loaded.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Retrieval Chain on Gemini Flash","metadata":{}},{"cell_type":"code","source":"from langchain_google_genai import ChatGoogleGenerativeAI\nllm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=0.3, top_p=0.85)\n\nfrom langchain.chains import RetrievalQAWithSourcesChain\nchain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=retriever)\n\nfrom langchain import PromptTemplate\nfrom langchain.schema import StrOutputParser\nfrom langchain.schema.prompt_template import format_document\nfrom langchain.schema.runnable import RunnablePassthrough\n\nllm_prompt_template = \"\"\"You are an assistant for question-answering tasks with advanced analytical and reasoning capabilities.\nUse the following context to answer the question.\nIf you don't know the answer, try to think of it without context.\\n\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\"\n\nllm_prompt = PromptTemplate.from_template(llm_prompt_template)\n\nprint(llm_prompt)\n\nrag_chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | llm_prompt\n    | llm\n    | StrOutputParser()\n)\n\n# Invoke the chain with example questions\nresponses = [\n    rag_chain.invoke(\"What are the 3 secondary supports of life?\"),\n    rag_chain.invoke(\"Reduced Therapy\"),\n    rag_chain.invoke(\"How to deal with heart disease\"),\n    rag_chain.invoke(\"What asanas should I do if I have imbalance in strnegth of my left and right arm?\"),\n    rag_chain.invoke(\"How can I make my tea better?\"),\n    rag_chain.invoke(\"Teach me in detail about dosas and how do I find mine?\"),\n    rag_chain.invoke(\"I have a Vatta-Pita imbalance. Help me\")\n]\n\n# Print the responses\nfor response in responses:\n    print(response)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nwhile True:\n    question=input(\"Ask a question\")\n    if \"stop\" in question:\n        break\n    print(question+\"\\n\\n\")\n    response=rag_chain.invoke(question)\n    print(response+\"\\n\\n\")","metadata":{},"outputs":[],"execution_count":null}]}